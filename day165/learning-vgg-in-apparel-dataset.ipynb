{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import modules","metadata":{}},{"cell_type":"code","source":"!pip install imutils\n!pip install loguru","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp ../input/vgg-simple/vgg.py /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vgg import *\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import SGD, Adam, Adagrad\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TerminateOnNaN, TensorBoard, ReduceLROnPlateau\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport argparse\nimport random\nimport pickle\nimport cv2\nimport os\nimport copy\nimport sys\nfrom loguru import logger","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nlogging.disable(logging.WARNING)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nlogger.debug(\"All modules imported\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cur_dir = os.getcwd()\ndata_dir = os.path.join(cur_dir, \"../input/apparel-images-dataset\")\noutput_dir = os.path.join(cur_dir, \"./\")\n\nlogger.debug(\"[INFO] loading images on progres...\")\ndata = []\nlabels = []\n\n# Grab the image paths and shuffle them\nimagePaths = sorted(list(paths.list_images(data_dir)))\nrandom.seed(2)\nrandom.shuffle(imagePaths)\n\nIMAGE_WIDTH, IMAGE_HEIGHT = 64, 64\n\nfor imagePath in imagePaths:\n    # Load the image\n    image = cv2.imread(imagePath)\n    \n    # Resize it\n    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n    \n    # Append data\n    data.append(image)\n    \n    # Extract the class label\n    label = imagePath.split(os.path.sep)[-2]\n    labels.append(label)\n    \nlogger.debug(\"[INFO] data load complete...\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row, col = 2,6\nfig, axs = plt.subplots(row, col, figsize=(15,7))\n\ncount = 0\nfor r in range(row):\n    for ax in axs[r]:\n        ax.imshow(cv2.cvtColor(data[count], cv2.COLOR_BGR2RGB))\n        ax.set_title(labels[count])\n        ax.grid(False)\n        count = count + 1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the raw pixel intensities to the range [0,1]\ndata = np.array(data, dtype='float') / 255.0\nlabels = np.array(labels)\n\n# Binarize labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\n\n# Save the encoder to output directory\nwith open(os.path.join(output_dir, \"labels\"), \"wb\") as f:\n    pickle.dump(lb, f)\n    \n# Randomly split (15% test and 85% train)\ntrain_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.15, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug = ImageDataGenerator(rotation_range=45, width_shift_range=0.1,\n                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                        horizontal_flip=True, fill_mode=\"nearest\")\n\n# Initialize VGG\nmodel = VGGNet.build(width=IMAGE_WIDTH, height=IMAGE_HEIGHT,\n                    depth=3, classes=len(lb.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize learning rate\nINIT_LR = 0.0007\nEPOCHS = 100\nBS = 64\n\n# Checkpoints between the training steps\nmodel_checkpoint = ModelCheckpoint(filepath=\"VGG_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5\",\n                                  monitor='val_loss',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=False,\n                                  mode='auto',\n                                  period=20)\n\n# Terminating of training if the loss become NaN\nterminate_on_nan = TerminateOnNaN()\n\n# Using tensorboard for visualization\nt_board = TensorBoard(log_dir='./logs',\n                      histogram_freq=0,\n                      batch_size=32,\n                      write_graph=True,\n                      write_grads=False,\n                      write_images=False,\n                      embeddings_freq=0,\n                      update_freq='epoch')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=10, min_lr=0.00001)\n\ncallbacks = [model_checkpoint, t_board, terminate_on_nan, reduce_lr]\n\n# Initialize the model and optimizers\nopt = Adam(lr=INIT_LR, beta_1=0.9, beta_2=0.999, amsgrad=False)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=opt,\n              metrics=['accuracy'])\n\n# Training the network\nlogger.debug(\"Training the network...\")\nH = model.fit_generator(aug.flow(train_X, train_y, batch_size=BS),\n                        validation_data=(test_X, test_y), steps_per_epoch=len(train_X) // BS,\n                        epochs=EPOCHS, callbacks=callbacks)\n\n# Save the model locally for use later\nmodel_path = os.path.join(output_dir, \"trained_VGG_model.h5\")\nmodel.save(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the network\nlogger.debug(\"Making predictions and evaluating the trained model\")\npredictions = model.predict(test_X, batch_size=32)\nprint(classification_report(test_y.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))\n\n# Plot the training loss and accuracy\nn = np.arange(0, EPOCHS)\nplt.figure()\nplt.plot(N, H.history['loss'], label='train_loss')\nplt.plot(N, H.history['val_loss'], label='val_loss')\nplt.plot(N, H.history['acc'], label='train_acc')\nplt.plot(N, H.history['val_acc'], label='val_acc')\nplt.title(\"Training/Validation Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.savefig(os.path.join(output_dir, \"vggnet_plot.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}