{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-invasion",
   "metadata": {},
   "source": [
    "# Predict Twitter Personality Types\n",
    "\n",
    "Tutorial: [The Assembly](https://www.youtube.com/watch?v=n1TCvsKUEZ8&t=377s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-advisory",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "public-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import array\n",
    "import csv\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('./newfrequency300.csv', 'rt')\n",
    "csv_reader = csv.reader(csv_file)\n",
    "mydict = {row[1]:int(row[0]) for row in csv_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "criminal-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INFP': 0,\n",
       " 'INFJ': 1,\n",
       " 'ENFP': 2,\n",
       " 'INTJ': 3,\n",
       " 'INTP': 4,\n",
       " 'ISFJ': 5,\n",
       " 'ENFJ': 6,\n",
       " 'ENTJ': 7,\n",
       " 'ISTJ': 8,\n",
       " 'rt': 9,\n",
       " 'ESTJ': 10,\n",
       " 'ISFP': 11,\n",
       " 'ISTP': 12,\n",
       " 'i': 13,\n",
       " 'ESFJ': 14,\n",
       " 'ESTP': 15,\n",
       " 'ESFP': 16,\n",
       " 'like': 17,\n",
       " 'it': 18,\n",
       " 'the': 19,\n",
       " \"i'm\": 20,\n",
       " 'get': 21,\n",
       " 'love': 22,\n",
       " 'amp': 23,\n",
       " 'one': 24,\n",
       " \"don't\": 25,\n",
       " 'time': 26,\n",
       " 'go': 27,\n",
       " 'peopl': 28,\n",
       " 'day': 29,\n",
       " 'make': 30,\n",
       " 'know': 31,\n",
       " 'this': 32,\n",
       " 'good': 33,\n",
       " 'thank': 34,\n",
       " 'want': 35,\n",
       " 'you': 36,\n",
       " 'look': 37,\n",
       " 'think': 38,\n",
       " 'a': 39,\n",
       " 'new': 40,\n",
       " 'thing': 41,\n",
       " 'need': 42,\n",
       " 'that': 43,\n",
       " 'see': 44,\n",
       " 'feel': 45,\n",
       " 'today': 46,\n",
       " 'my': 47,\n",
       " 'what': 48,\n",
       " 'work': 49,\n",
       " 'say': 50,\n",
       " 'video': 51,\n",
       " 'year': 52,\n",
       " 'de': 53,\n",
       " 'realli': 54,\n",
       " 'much': 55,\n",
       " 'life': 56,\n",
       " 'so': 57,\n",
       " 'via': 58,\n",
       " \"you'r\": 59,\n",
       " 'u': 60,\n",
       " \"can't\": 61,\n",
       " 'got': 62,\n",
       " 'happi': 63,\n",
       " 'still': 64,\n",
       " 'and': 65,\n",
       " 'would': 66,\n",
       " 'watch': 67,\n",
       " 'take': 68,\n",
       " 'right': 69,\n",
       " 'come': 70,\n",
       " 'even': 71,\n",
       " 'never': 72,\n",
       " 'if': 73,\n",
       " 'us': 74,\n",
       " 'way': 75,\n",
       " 'best': 76,\n",
       " 'great': 77,\n",
       " 'back': 78,\n",
       " \"i'v\": 79,\n",
       " '@youtub': 80,\n",
       " 'tri': 81,\n",
       " 'use': 82,\n",
       " 'me': 83,\n",
       " 'first': 84,\n",
       " 'friend': 85,\n",
       " 'que': 86,\n",
       " 'let': 87,\n",
       " 'e': 88,\n",
       " 'we': 89,\n",
       " 'fuck': 90,\n",
       " 'how': 91,\n",
       " 'read': 92,\n",
       " 'live': 93,\n",
       " 'when': 94,\n",
       " 'someon': 95,\n",
       " 'oh': 96,\n",
       " 'is': 97,\n",
       " 'to': 98,\n",
       " 'ever': 99,\n",
       " 'also': 100,\n",
       " 'alway': 101,\n",
       " 'person': 102,\n",
       " 'w': 103,\n",
       " 'he': 104,\n",
       " 'trump': 105,\n",
       " 'start': 106,\n",
       " 'well': 107,\n",
       " 'last': 108,\n",
       " 'help': 109,\n",
       " 'im': 110,\n",
       " 'in': 111,\n",
       " 'show': 112,\n",
       " 'world': 113,\n",
       " 'there': 114,\n",
       " 'everi': 115,\n",
       " 'talk': 116,\n",
       " 'lol': 117,\n",
       " 'just': 118,\n",
       " 'week': 119,\n",
       " 'hope': 120,\n",
       " 'pleas': 121,\n",
       " 'give': 122,\n",
       " 'actual': 123,\n",
       " 'but': 124,\n",
       " 'follow': 125,\n",
       " 'better': 126,\n",
       " 'call': 127,\n",
       " 'could': 128,\n",
       " 'guy': 129,\n",
       " 'yes': 130,\n",
       " 'girl': 131,\n",
       " 'no': 132,\n",
       " 'made': 133,\n",
       " 'find': 134,\n",
       " 'someth': 135,\n",
       " 'god': 136,\n",
       " 'play': 137,\n",
       " 'man': 138,\n",
       " 'women': 139,\n",
       " 'stop': 140,\n",
       " 'tell': 141,\n",
       " 'mean': 142,\n",
       " ':)': 143,\n",
       " 'book': 144,\n",
       " 'thought': 145,\n",
       " 'keep': 146,\n",
       " 'everyon': 147,\n",
       " 'wait': 148,\n",
       " \"i'll\": 149,\n",
       " 'why': 150,\n",
       " 'ask': 151,\n",
       " 'mani': 152,\n",
       " 'eu': 153,\n",
       " 'night': 154,\n",
       " 'chang': 155,\n",
       " 'check': 156,\n",
       " 'game': 157,\n",
       " 'tweet': 158,\n",
       " 'beauti': 159,\n",
       " 'happen': 160,\n",
       " 'la': 161,\n",
       " 'not': 162,\n",
       " 'for': 163,\n",
       " 'post': 164,\n",
       " 'miss': 165,\n",
       " 'bad': 166,\n",
       " 'end': 167,\n",
       " 'next': 168,\n",
       " 'n': 169,\n",
       " 'l': 170,\n",
       " \"didn't\": 171,\n",
       " 'lot': 172,\n",
       " 'final': 173,\n",
       " 'your': 174,\n",
       " 'littl': 175,\n",
       " 'said': 176,\n",
       " 'real': 177,\n",
       " 'gonna': 178,\n",
       " 'she': 179,\n",
       " 'sure': 180,\n",
       " 'two': 181,\n",
       " 'word': 182,\n",
       " 'die': 183,\n",
       " 'may': 184,\n",
       " 'do': 185,\n",
       " 'learn': 186,\n",
       " 'shit': 187,\n",
       " 'hate': 188,\n",
       " \"doesn't\": 189,\n",
       " 'photo': 190,\n",
       " 'song': 191,\n",
       " 'na': 192,\n",
       " 'here': 193,\n",
       " 'stori': 194,\n",
       " 'free': 195,\n",
       " 'twitter': 196,\n",
       " 'everyth': 197,\n",
       " 'lt': 198,\n",
       " 'rememb': 199,\n",
       " 'part': 200,\n",
       " 'put': 201,\n",
       " 'omg': 202,\n",
       " 'all': 203,\n",
       " 'believ': 204,\n",
       " 'win': 205,\n",
       " 'long': 206,\n",
       " 'write': 207,\n",
       " 'care': 208,\n",
       " 'hard': 209,\n",
       " 'th': 210,\n",
       " 'amaz': 211,\n",
       " 'listen': 212,\n",
       " 'tonight': 213,\n",
       " 'home': 214,\n",
       " 'support': 215,\n",
       " 'done': 216,\n",
       " 'kid': 217,\n",
       " 'hour': 218,\n",
       " 'yeah': 219,\n",
       " 'old': 220,\n",
       " 'heart': 221,\n",
       " 'name': 222,\n",
       " \"we'r\": 223,\n",
       " 'fun': 224,\n",
       " 'share': 225,\n",
       " 'school': 226,\n",
       " 'pretti': 227,\n",
       " 'ok': 228,\n",
       " 'nice': 229,\n",
       " 'anoth': 230,\n",
       " 'cri': 231,\n",
       " 'gt': 232,\n",
       " 'birthday': 233,\n",
       " 'around': 234,\n",
       " 'morn': 235,\n",
       " \"they'r\": 236,\n",
       " 'alreadi': 237,\n",
       " 'on': 238,\n",
       " 'who': 239,\n",
       " 'b': 240,\n",
       " 'white': 241,\n",
       " 'of': 242,\n",
       " 'they': 243,\n",
       " 'wonder': 244,\n",
       " 'cute': 245,\n",
       " 'big': 246,\n",
       " 'music': 247,\n",
       " 'are': 248,\n",
       " 'anyon': 249,\n",
       " 'differ': 250,\n",
       " \"isn't\": 251,\n",
       " 'open': 252,\n",
       " 'true': 253,\n",
       " 'ya': 254,\n",
       " 'job': 255,\n",
       " 'di': 256,\n",
       " 'mayb': 257,\n",
       " 'idea': 258,\n",
       " 'more': 259,\n",
       " 'sinc': 260,\n",
       " 'favorit': 261,\n",
       " 'wish': 262,\n",
       " 'sleep': 263,\n",
       " 'anyth': 264,\n",
       " 'though': 265,\n",
       " 'movi': 266,\n",
       " 'black': 267,\n",
       " 'now': 268,\n",
       " 'noth': 269,\n",
       " 'without': 270,\n",
       " 'away': 271,\n",
       " 'okay': 272,\n",
       " 'hous': 273,\n",
       " 'art': 274,\n",
       " 'sorri': 275,\n",
       " 'kind': 276,\n",
       " 'month': 277,\n",
       " 'excit': 278,\n",
       " 'face': 279,\n",
       " 'point': 280,\n",
       " 'boy': 281,\n",
       " 'se': 282,\n",
       " 'tomorrow': 283,\n",
       " 'place': 284,\n",
       " 'enough': 285,\n",
       " 'can': 286,\n",
       " 'interest': 287,\n",
       " 'question': 288,\n",
       " 'plan': 289,\n",
       " 'type': 290,\n",
       " \"i'd\": 291,\n",
       " 'liter': 292,\n",
       " 'turn': 293,\n",
       " 'haha': 294,\n",
       " 'da': 295,\n",
       " 'meet': 296,\n",
       " 'found': 297,\n",
       " 'sound': 298,\n",
       " 'ur': 299,\n",
       " 'break': 300}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-owner",
   "metadata": {},
   "source": [
    "## First Models: PJFinalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gorgeous-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "with open(\"./PJFinaltest.csv\", 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = [row[0] for row in reader]\n",
    "    \n",
    "with open(\"./PJFinaltest.csv\", 'rt') as f:\n",
    "    csv_reader_1 = csv.reader(f)\n",
    "    for rows in csv_reader_1:\n",
    "        y.append([int(rows[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "packed-bridges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tropical-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=mydict, min_df=1)\n",
    "x = vectorizer.fit_transform(corpus).toarray()\n",
    "result = np.append(x, y, axis=1)\n",
    "X = pd.DataFrame(result)\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiac-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test = X.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "equipped-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105366</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34676</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47867</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265610 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8         9    ...  292  293  \\\n",
       "228143  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.252796  ...  0.0  0.0   \n",
       "105366  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "289453  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.189386  ...  0.0  0.0   \n",
       "143984  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "275145  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.000000  ...  0.0  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...  ...  ...   \n",
       "37149   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "18895   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "115574  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "34676   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "47867   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "\n",
       "        294  295  296  297  298  299  300  301  \n",
       "228143  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "105366  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "289453  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "143984  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "275145  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "37149   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "18895   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "115574  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "34676   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "47867   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[265610 rows x 302 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "difficult-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66403 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9    ...  292  293  294  \\\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "7       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "26      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "27      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "331999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "332006  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "332007  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "332008  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "332009  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "        295  296  297  298  299  300  301  \n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5       0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "7       0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "26      0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "27      0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "331999  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "332006  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "332007  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "332008  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "332009  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[66403 rows x 302 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comprehensive-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[301]\n",
    "y_test = test[301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accepted-links",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265610, 302)\n",
      "(66403, 302)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convenient-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(301,axis=1)\n",
    "X_test = test.drop(301, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "meaning-camera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blank-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"BNPJFinal.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "serious-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-classics",
   "metadata": {},
   "source": [
    "## Second Models: SNFinalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opened-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "with open(\"./SNFinaltest.csv\", 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = [rows[0] for rows in reader]\n",
    "    \n",
    "with open(\"./SNFinaltest.csv\", 'rt') as f:\n",
    "    csv_reader_1 = csv.reader(f)\n",
    "    for rows in csv_reader_1:\n",
    "        y.append([int(rows[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exciting-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=mydict, min_df=1)\n",
    "x = vectorizer.fit_transform(corpus).toarray()\n",
    "result = np.append(x, y, axis=1)\n",
    "X = pd.DataFrame(result)\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handled-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test = X.drop(train.index)\n",
    "y_train = train[301]\n",
    "y_test = test[301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expressed-shell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188541, 302)\n",
      "(47135, 302)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "charged-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(301, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "raised-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(301, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "toxic-friendly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wrapped-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"BNSNFinal.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prescription-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-sleeping",
   "metadata": {},
   "source": [
    "## Third Model: IEFinalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "executive-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "with open(\"./IEFinaltest.csv\", 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = [rows[0] for rows in reader]\n",
    "    \n",
    "with open(\"./IEFinaltest.csv\", 'rt') as f:\n",
    "    csv_reader_1 = csv.reader(f)\n",
    "    for rows in csv_reader_1:\n",
    "        y.append([int(rows[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "north-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=mydict, min_df=1)\n",
    "x = vectorizer.fit_transform(corpus).toarray()\n",
    "result = np.append(x, y, axis=1)\n",
    "X = pd.DataFrame(result)\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "substantial-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test = X.drop(train.index)\n",
    "y_train = train[301]\n",
    "y_test = test[301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "opposed-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342280, 302)\n",
      "(85570, 302)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "coastal-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(301, axis=1)\n",
    "X_test = test.drop(301, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cloudy-index",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adjacent-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"BNIEFinal.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "impossible-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-estimate",
   "metadata": {},
   "source": [
    "## Fourth Model: TFFinalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "statewide-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "with open(\"./TFFinaltest.csv\", 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    corpus = [rows[0] for rows in reader]\n",
    "    \n",
    "with open(\"./TFFinaltest.csv\", 'rt') as f:\n",
    "    csv_reader_1 = csv.reader(f)\n",
    "    for rows in csv_reader_1:\n",
    "        y.append([int(rows[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "graphic-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=mydict, min_df=1)\n",
    "x = vectorizer.fit_transform(corpus).toarray()\n",
    "result = np.append(x, y, axis=1)\n",
    "X = pd.DataFrame(result)\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "respiratory-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test = X.drop(train.index)\n",
    "y_train = train[301]\n",
    "y_test = test[301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "black-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256000, 302)\n",
      "(64000, 302)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "homeless-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(301, axis=1)\n",
    "X_test = test.drop(301, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fifteen-midwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "coastal-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"BNTFFinal.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "rural-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-fantasy",
   "metadata": {},
   "source": [
    "## Connect Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "widespread-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from unidecode import unidecode\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "import tweepy\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-photograph",
   "metadata": {},
   "source": [
    "## Add token key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-reality",
   "metadata": {},
   "source": [
    "You should have the API Key from [developer twitter](https://developer.twitter.com/en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "technical-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckey='BxDQXW4F8OAHAF9In34ksMErO' \n",
    "csecret='IEupQjHxxDkhzC6VwWd4toqD407ZJdrLx9crICD2gKISATaZQr' \n",
    "atoken='2418452160-EPk5pvfHtgn1FHKv9QuMhL3HuahZjxqwr6i7qdz' \n",
    "asecret='fyIxH6XgVt2CQmMq3cSzCEHoH0yzNL1iXoE8xStmYlzAS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "broadband-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-supervision",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "moving-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # MoUTH\n",
    "    )\"\"\"\n",
    "    \n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\" # Emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\" # Symbols & Pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\" # Transport & Map Symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\" # Flags (iOS)\n",
    "                          \"]+\", flags=re.UNICODE)\n",
    "\n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r'(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)', # Hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "    \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # Numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # Words with - and ' \n",
    "    r'(?:[\\w_]+)', # Other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "romance-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_re = re.compile('(' + '|'.join(regex_str) + ')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^' + emoticons_str + '$', re.VERBOSE | re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-religion",
   "metadata": {},
   "source": [
    "## Declaring important function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "herbal-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    "\n",
    "\n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens=[token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "        \n",
    "\n",
    "def preproc(s):\n",
    "    s = unidecode(s)\n",
    "    POSTagger = preprocess(s)\n",
    "    \n",
    "    tweet = ' '.join(POSTagger)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_tokens = word_tokenize(tweet)\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in POSTagger:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "            \n",
    "    stemmed_sentence=[]\n",
    "    stemmer2 = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    for w in filtered_sentence:\n",
    "        stemmed_sentence.append(stemmer2.stem(w))\n",
    "        \n",
    "    temp = ' '.join(c for c in stemmed_sentence if c not in string.punctuation)\n",
    "    preProcessed = temp.split(\" \")\n",
    "    final = []\n",
    "    \n",
    "    for i in preProcessed:\n",
    "        if i not in final:\n",
    "            if i.isdigit():\n",
    "                pass\n",
    "            else:\n",
    "                if 'http' not in i:\n",
    "                    final.append(i)\n",
    "    \n",
    "    temp1 = ' '.join(c for c in final)\n",
    "    return temp1\n",
    "\n",
    "\n",
    "def getTweets(user):\n",
    "    csvFile = open('user.csv', 'a', newline='')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    try:\n",
    "        for i in range(0,4):\n",
    "            tweets = api.user_timeline(screen_name=user, count=1000, include_rts=True, page=i)\n",
    "            for status in tweets:\n",
    "                tw=preproc(status.text)\n",
    "                if tw.find(\" \") == -1:\n",
    "                    tw = \"blank\"\n",
    "                csvWriter.writerow([tw])\n",
    "    except tweepy.TweepError:\n",
    "        print(\"Failed run the command on the user, Skipping...\")\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sticky-papua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the twitter account handle: @tim_fargo\n"
     ]
    }
   ],
   "source": [
    "username = input(\"Please enter the twitter account handle: \")\n",
    "getTweets(username)\n",
    "\n",
    "with open(f\"user.csv\", 'rt') as f:\n",
    "    csvReader = csv.reader(f)\n",
    "    tweetList=[rows[0] for rows in csvReader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "affecting-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"newfrequency300.csv\", 'rt') as f:\n",
    "    csvReader=csv.reader(f)\n",
    "    mydict={rows[1]: int(rows[0]) for rows in csvReader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "enabling-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=mydict, min_df=1)\n",
    "x = vectorizer.fit_transform(tweetList).toarray()\n",
    "df = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-upset",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "focused-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_IE = pickle.load(open(\"BNIEFinal.sav\", 'rb'))\n",
    "model_SN = pickle.load(open(\"BNSNFinal.sav\", 'rb'))\n",
    "model_TF = pickle.load(open(\"BNTFFinal.sav\", 'rb'))\n",
    "model_PJ = pickle.load(open(\"BNPJFinal.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cellular-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "IE = model_IE.predict(df)\n",
    "SN = model_SN.predict(df)\n",
    "TF = model_TF.predict(df)\n",
    "PJ = model_PJ.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-proposal",
   "metadata": {},
   "source": [
    "## If/Else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "forbidden-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 424)]\n",
      "[(0.0, 424)]\n",
      "[(1.0, 423)]\n",
      "[(0.0, 516)]\n"
     ]
    }
   ],
   "source": [
    "# Introvert / Extrovert\n",
    "b = Counter(IE)\n",
    "value = b.most_common(1)\n",
    "print(value)\n",
    "if value[0][0] == 1.0:\n",
    "    answer.append(\"I\")\n",
    "else:\n",
    "    answer.append(\"E\")\n",
    "\n",
    "# Sensing / iNtuition\n",
    "b = Counter(IE)\n",
    "value = b.most_common(1)\n",
    "print(value)\n",
    "if value[0][0] == 1.0:\n",
    "    answer.append(\"S\")\n",
    "else:\n",
    "    answer.append(\"N\")\n",
    "\n",
    "# Thinking / Feeling\n",
    "b = Counter(TF)\n",
    "value = b.most_common(1) \n",
    "print(value)\n",
    "if value[0][0] == 1:\n",
    "    answer.append(\"T\")\n",
    "else:\n",
    "    answer.append(\"F\")\n",
    "    \n",
    "# Perceiving Judging\n",
    "b = Counter(PJ)\n",
    "value = b.most_common(1)\n",
    "print(value)\n",
    "if value[0][0] == 1:\n",
    "    answer.append(\"P\")\n",
    "else:\n",
    "    answer.append(\"J\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-integral",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "happy-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's likely the personalities is ENTJ\n"
     ]
    }
   ],
   "source": [
    "mbti = \"\".join(answer)\n",
    "print(\"It's likely the personalities is\", mbti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-nicaragua",
   "metadata": {},
   "source": [
    "From the result we get that user @tim_fargo has ENTJ personality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
