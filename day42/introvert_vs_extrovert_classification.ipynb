{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "06cb67651ce969e244f20f184e33f4ddb1106793adfe07cf7ddc131c95c4012f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Introvert vs Extrovert Model\n",
    "\n",
    "Dataset : [Link](https://www.kaggle.com/datasnaek/mbti-type)\n",
    "\n",
    "Tutorial : [Gabriel Atkin](https://www.youtube.com/watch?v=s3g0MJcJZyA&list=PLFMqiVagrzLKQ4a37Jj87dl1ccK2RNzG-&index=19&ab_channel=GabrielAtkin)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing Modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/mbti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8675 entries, 0 to 8674\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   type    8675 non-null   object\n 1   posts   8675 non-null   object\ndtypes: object(2)\nmemory usage: 135.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
       "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(data):\n",
    "    texts = data['posts'].copy()\n",
    "    labels = data['type'].copy()\n",
    "\n",
    "    # Process text data\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    texts = [text.lower() for text in texts]\n",
    "    texts = [text.split() for text in texts]\n",
    "    texts = [[word.strip() for word in text] for text in texts]\n",
    "    texts = [[word for word in text if word not in stop_words] for text in texts]\n",
    "\n",
    "    vocab_length = 10000\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_length)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    texts = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    max_seq_len = np.max([len(text) for text in texts])\n",
    "\n",
    "    texts = pad_sequences(texts, maxlen=max_seq_len, padding='post')\n",
    "\n",
    "    # Process label\n",
    "    label_values = [\n",
    "        'INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'\n",
    "    ]\n",
    "\n",
    "    label_mapping = {label: np.int(label[0] == 'E') for label in label_values}\n",
    "\n",
    "    labels = labels.replace(label_mapping)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return texts, labels, max_seq_len, vocab_length, label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, max_seq_length, vocab_length, label_mapping = preprocess_inputs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Text sequences: (8675, 859)\n\nLabels: (8675,)\n\nMax Sequence Length 859\n\nVocab length: 10000\n\nLabel mapping: {'INFJ': 0, 'ENTP': 1, 'INTP': 0, 'INTJ': 0, 'ENTJ': 1, 'ENFJ': 1, 'INFP': 0, 'ENFP': 1, 'ISFP': 0, 'ISTP': 0, 'ISFJ': 0, 'ISTJ': 0, 'ESTP': 1, 'ESFP': 1, 'ESTJ': 1, 'ESFJ': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Text sequences:\", texts.shape)\n",
    "print(\"\\nLabels:\", labels.shape)\n",
    "print(\"\\nMax Sequence Length\", max_seq_length)\n",
    "print(\"\\nVocab length:\", vocab_length)\n",
    "print(\"\\nLabel mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, train_size=0.7, random_state=123)"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "152/152 [==============================] - 2775s 18s/step - loss: 0.5587 - accuracy: 0.7643 - auc: 0.6447 - val_loss: 0.4485 - val_accuracy: 0.8082 - val_auc: 0.8120\n",
      "Epoch 2/5\n",
      "152/152 [==============================] - 5089s 34s/step - loss: 0.0588 - accuracy: 0.9841 - auc: 0.9985 - val_loss: 0.5267 - val_accuracy: 0.7918 - val_auc: 0.7587\n",
      "Epoch 3/5\n",
      "152/152 [==============================] - 3575s 24s/step - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.7942 - val_auc: 0.7898\n",
      "Epoch 4/5\n",
      "152/152 [==============================] - 3950s 26s/step - loss: 7.0279e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.7959 - val_auc: 0.7865\n",
      "Epoch 5/5\n",
      "152/152 [==============================] - 3472s 23s/step - loss: 3.7040e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7984 - val_auc: 0.7839\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 512\n",
    "\n",
    "inputs = tf.keras.Input(shape=(max_seq_length,))\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_length,\n",
    "    output_dim=embedding_dim,\n",
    "    input_length=max_seq_length\n",
    ")(inputs)\n",
    "\n",
    "gru = tf.keras.layers.Bidirectional(\n",
    "      tf.keras.layers.GRU(\n",
    "          units=256,\n",
    "          return_sequences=True\n",
    "      )\n",
    "    )(embedding)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(gru)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    texts_train,\n",
    "    labels_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "source": [
    "## Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "82/82 [==============================] - 293s 4s/step - loss: 0.7376 - accuracy: 0.8075 - auc: 0.8043\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7375852465629578, 0.8075297474861145, 0.804264485836029]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.evaluate(texts_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn, gru_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: introver_extrovert_model\\assets\n",
      "INFO:tensorflow:Assets written to: introver_extrovert_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('introver_extrovert_model')"
   ]
  }
 ]
}