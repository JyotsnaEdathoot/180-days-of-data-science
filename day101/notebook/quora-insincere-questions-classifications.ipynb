{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# THIS IS UNSUCCESSFUL NOTEBOOK - DON'T FOLLOW","metadata":{}},{"cell_type":"markdown","source":"# Quora Insincere Questions Classifications\n\nOriginal: [Basic Model](https://www.kaggle.com/nitinaggarwal008/basic-model)","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow\n# !pip install --upgrade keras\n# !pip install --upgrade tensorflow\n# !pip install --upgrade tensorflow-gpu","metadata":{"execution":{"iopub.status.busy":"2021-09-08T06:54:06.176808Z","iopub.execute_input":"2021-09-08T06:54:06.177173Z","iopub.status.idle":"2021-09-08T06:54:06.180904Z","shell.execute_reply.started":"2021-09-08T06:54:06.177135Z","shell.execute_reply":"2021-09-08T06:54:06.179989Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\nfrom keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\nfrom keras.layers import Dense, Input, Embedding, Dropout, Activation, Conv1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.layers import Layer\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.models import Model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport string, re\nimport time\nimport math\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T06:57:17.240347Z","iopub.execute_input":"2021-09-08T06:57:17.240902Z","iopub.status.idle":"2021-09-08T06:57:25.168259Z","shell.execute_reply.started":"2021-09-08T06:57:17.240804Z","shell.execute_reply":"2021-09-08T06:57:25.167208Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"embed_size = 300\nmax_features = 53\nmaxlen = 70","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:19:01.792903Z","iopub.execute_input":"2021-09-08T07:19:01.793842Z","iopub.status.idle":"2021-09-08T07:19:01.801590Z","shell.execute_reply.started":"2021-09-08T07:19:01.793762Z","shell.execute_reply":"2021-09-08T07:19:01.800279Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def clean(text):\n    # Remove punctuation\n    text = text.translate(string.punctuation)\n    \n    # Convert words to lower case and split\n    text = text.lower()\n    \n    ## remove stop words\n    # text = text.split()\n    # stops = set(stopwords.words(\"english\"))\n    # text = [w for w in text if not w in stops and len(w) >= 3]\n    \n    text = \" \".join(text)\n    \n    # Clean the text\n    text = re.sub(r\"[^A_Za-z0-9^,!>\\/'+-=]\", \" \", text)\n    text = re.sub(r\"what's\", \"what is\", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\"\\'re\", \"are\", text)\n    text = re.sub(r\"\\'d\", \"would\", text)\n    text = re.sub(r\"\\'ll\", \"will\", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" \", text)\n    text = re.sub(r\"!\", \" ! \", text)\n    text = re.sub(r\"\\/\", \" \", text)\n    text = re.sub(r\"\\^\", \" ^ \", text)\n    text = re.sub(r\"\\+\", \" + \", text)\n    text = re.sub(r\"\\-\", \" - \", text)\n    text = re.sub(r\"\\=\", \" = \", text)\n    text = re.sub(r\"'\", \" \", text)\n    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    text = re.sub(r\":\", \" : \", text)\n    text = re.sub(r\" e g \", \" eg\", text)\n    text = re.sub(r\" b g\", \" bg\", text)\n    text = re.sub(r\" u s\", \" american\", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11\", \"911\", text)\n    text = re.sub(r\"e - mail\", \"email\", text)\n    text = re.sub(r\"j k\", \"jk\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n    text = re.sub(\"  +\", \" \", text)\n    \n    # text = text.split()\n    # stemmer = SnowballStemmer(\"english\")\n    # stemmed_words = [stemmer.stem(word) for word in text]\n    # text = \" \".join(stemmed_words)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-09-08T06:57:27.885782Z","iopub.execute_input":"2021-09-08T06:57:27.886182Z","iopub.status.idle":"2021-09-08T06:57:27.900246Z","shell.execute_reply.started":"2021-09-08T06:57:27.886149Z","shell.execute_reply":"2021-09-08T06:57:27.899411Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Load training and test data: Convert into padded sentences for keras model inputs","metadata":{}},{"cell_type":"code","source":"def load_and_prec():\n    df_train = pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\")\n    df_test = pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\")\n    print(\"Train shape:\", df_train.shape)\n    print(\"Test shape:\", df_test.shape)\n    \n    df_train['clean_text'] = df_train['question_text'].apply(clean)\n    df_test['clean_text'] = df_test['question_text'].apply(clean)\n    \n    # Split into train and val\n    df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=21)\n    \n    # Fill up the missing values\n    X_train = df_train['clean_text'].fillna(\"_##_\").values\n    X_test = df_test['clean_text'].fillna(\"_##_\").values\n    X_val = df_val['clean_text'].fillna(\"_##_\").values\n    \n    # Tokenize the sentences\n    tokenizer = Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(list(X_train))\n    X_train = tokenizer.texts_to_sequences(X_train)\n    X_test = tokenizer.texts_to_sequences(X_test)\n    X_val = tokenizer.texts_to_sequences(X_val)\n    \n    # Padding\n    X_train = pad_sequences(X_train, maxlen=maxlen)\n    X_test = pad_sequences(X_test, maxlen=maxlen)\n    X_val = pad_sequences(X_val, maxlen=maxlen)\n    \n    # Get the target values\n    y_train = df_train['target'].values\n    y_val = df_val['target'].values\n    \n    # Shuffle data\n    np.random.seed(21)\n    train_idx = np.random.permutation(len(X_train))\n    val_idx = np.random.permutation(len(X_val))\n    \n    X_train = X_train[train_idx]\n    X_val = X_val[val_idx]\n    y_train = y_train[train_idx]\n    y_val = y_val[val_idx]\n    \n    return X_train, X_val, X_test, y_train, y_val, tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2021-09-08T06:57:29.833938Z","iopub.execute_input":"2021-09-08T06:57:29.834646Z","iopub.status.idle":"2021-09-08T06:57:29.845976Z","shell.execute_reply.started":"2021-09-08T06:57:29.834575Z","shell.execute_reply":"2021-09-08T06:57:29.844714Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Embedding setup\n\nSource: [keras embeddings](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)","metadata":{}},{"cell_type":"code","source":"!unzip ../input/quora-insincere-questions-classification/embeddings.zip","metadata":{"execution":{"iopub.status.busy":"2021-09-08T06:57:30.812542Z","iopub.execute_input":"2021-09-08T06:57:30.812931Z","iopub.status.idle":"2021-09-08T07:01:00.806249Z","shell.execute_reply.started":"2021-09-08T06:57:30.812899Z","shell.execute_reply":"2021-09-08T07:01:00.804773Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Archive:  ../input/quora-insincere-questions-classification/embeddings.zip\n   creating: GoogleNews-vectors-negative300/\n   creating: glove.840B.300d/\n   creating: paragram_300_sl999/\n   creating: wiki-news-300d-1M/\n  inflating: glove.840B.300d/glove.840B.300d.txt  \n  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n  inflating: paragram_300_sl999/README.txt  \n  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n","output_type":"stream"}]},{"cell_type":"code","source":"def load_gloves(word_index):\n    EMBEDDING_FILE = './glove.840B.300d/glove.840B.300d.txt'\n    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n    \n    all_embs = np.stack(embeddings_index.values())\n    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n    \n    # word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    \n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n            \n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:01:00.808446Z","iopub.execute_input":"2021-09-08T07:01:00.808824Z","iopub.status.idle":"2021-09-08T07:01:00.821428Z","shell.execute_reply.started":"2021-09-08T07:01:00.808783Z","shell.execute_reply":"2021-09-08T07:01:00.820002Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def load_fasttext(word_index):\n    EMBEDDING_FILE = './wiki-news-300d-1M/wiki-news-300d-1M.vec'\n    def get_coefs(word, * arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o) > 100)\n    \n    all_embs = np.stack(embeddings_index.values())\n    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n    \n    # word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    \n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n            \n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:01:00.823416Z","iopub.execute_input":"2021-09-08T07:01:00.823809Z","iopub.status.idle":"2021-09-08T07:01:04.602752Z","shell.execute_reply.started":"2021-09-08T07:01:00.823772Z","shell.execute_reply":"2021-09-08T07:01:04.601712Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_para(word_index):\n    EMBEDDING_FILE = './paragram_300_sl999/paragram_300_sl999.txt'\n    def get_coefs(word, * arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o) > 100)\n    \n    all_embs = np.stack(embeddings_index.values())\n    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n    \n    # word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    \n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n            \n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:01:04.604561Z","iopub.execute_input":"2021-09-08T07:01:04.604969Z","iopub.status.idle":"2021-09-08T07:01:06.374730Z","shell.execute_reply.started":"2021-09-08T07:01:04.604925Z","shell.execute_reply":"2021-09-08T07:01:06.373665Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Define LSTM Model Architecture","metadata":{}},{"cell_type":"code","source":"def model_lstm_du(embedding_matrix):\n    inp = Input(shape=(maxlen,))\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    conc = concatenate([avg_pool, max_pool])\n    conc = Dense(64, activation='relu')(conc)\n    conc = Dropout(0.1)(conc)\n    outp = Dense(1, activation=\"sigmoid\")(conc)\n    \n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:19:25.492417Z","iopub.execute_input":"2021-09-08T07:19:25.492875Z","iopub.status.idle":"2021-09-08T07:19:25.502756Z","shell.execute_reply.started":"2021-09-08T07:19:25.492837Z","shell.execute_reply":"2021-09-08T07:19:25.501008Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Define Training Functions","metadata":{}},{"cell_type":"code","source":"def train_pred(model, epochs=5):\n    for e in range(epochs):\n        model.fit(X_train, y_train, batch_size=512, epochs=1, validation_data=(X_val, y_val))\n        y_val_pred = model.predict([X_val], batch_size=1024, verbose=0)\n        \n        best_thresh = 0.5\n        best_score = 0.0\n        for thresh in np.arange(0.1, 0.501, 0.01):\n            thresh = np.round(thresh, 2)\n            score = metrics.f1_score(y_val, (y_val_pred > thresh).astype(int))\n            if score > best_score:\n                best_thresh = thresh\n                best_score = score\n                \n            print(\"Val F! Score: {:.4f}\".format(best_score))\n            \n        y_test_pred = model.predict([X_test], batch_size=1024, verbose=0)\n        return y_val_pred, y_test_pred, best_score","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:01:07.992953Z","iopub.execute_input":"2021-09-08T07:01:07.993782Z","iopub.status.idle":"2021-09-08T07:01:08.003942Z","shell.execute_reply.started":"2021-09-08T07:01:07.993717Z","shell.execute_reply":"2021-09-08T07:01:08.002801Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"%%time\nX_train, X_val, X_test, y_train, y_val, word_index = load_and_prec()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:01:08.005329Z","iopub.execute_input":"2021-09-08T07:01:08.005690Z","iopub.status.idle":"2021-09-08T07:06:34.205197Z","shell.execute_reply.started":"2021-09-08T07:01:08.005654Z","shell.execute_reply":"2021-09-08T07:06:34.202436Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Train shape: (1306122, 3)\nTest shape: (375806, 2)\nCPU times: user 5min 20s, sys: 3.58 s, total: 5min 23s\nWall time: 5min 26s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the embeddings","metadata":{}},{"cell_type":"code","source":"%%time\nembedding_matrix_1 = load_gloves(word_index)\n# embedding_matrix_2 = load_fasttext(word_index)\n# embedding_matrix_3 = load_para(word_index)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:06:34.207820Z","iopub.execute_input":"2021-09-08T07:06:34.208143Z","iopub.status.idle":"2021-09-08T07:11:27.838126Z","shell.execute_reply.started":"2021-09-08T07:06:34.208111Z","shell.execute_reply":"2021-09-08T07:11:27.836772Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py:1321: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n  exec(code, glob, local_ns)\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 4min 40s, sys: 13 s, total: 4min 53s\nWall time: 4min 53s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Run the model","metadata":{}},{"cell_type":"code","source":"def model_lstm_du(embedding_matrix):\n    inp = Input(shape=(maxlen,))\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n    # x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    conc = concatenate([avg_pool, max_pool])\n    conc = Dense(64, activation=\"relu\")(conc)\n    conc = Dropout(0.1)(conc)\n    outp = Dense(1, activation=\"sigmoid\")(conc)\n    \n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:25:54.939716Z","iopub.execute_input":"2021-09-08T07:25:54.940252Z","iopub.status.idle":"2021-09-08T07:25:54.947240Z","shell.execute_reply.started":"2021-09-08T07:25:54.940218Z","shell.execute_reply":"2021-09-08T07:25:54.946453Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def train_pred(model, epochs=2):\n    for e in range(epochs):\n        model.fit(X_train, y_train, batch_size=2048, epochs=1, validation_data=(X_val, y_val))\n        y_val_pred = model.predict([X_val], batch_size=2048, verbose=1)\n\n        best_thresh = 0.5\n        best_score = 0.0\n        for thresh in np.arange(0.1, 0.501, 0.01):\n            thresh = np.round(thresh, 2)\n            score = metrics.f1_score(y_val, (y_val_pred > thresh).astype(int))\n            if score > best_score:\n                best_thresh = thresh\n                best_score = score\n\n        print(\"Val F1 Score: {:.4f}\".format(best_score))\n    y_test_pred = model.predict([X_test], batch_size=2048, verbose=1)\n    return y_val_pred, y_test_pred, best_score","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:33:36.129866Z","iopub.execute_input":"2021-09-08T07:33:36.130454Z","iopub.status.idle":"2021-09-08T07:33:36.142239Z","shell.execute_reply.started":"2021-09-08T07:33:36.130405Z","shell.execute_reply":"2021-09-08T07:33:36.141065Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"%%time\ny_val_pred, y_test_pred, best_score = train_pred(model_lstm_du(embedding_matrix_1), epochs=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:33:36.794912Z","iopub.execute_input":"2021-09-08T07:33:36.795288Z","iopub.status.idle":"2021-09-08T07:34:57.897119Z","shell.execute_reply.started":"2021-09-08T07:33:36.795254Z","shell.execute_reply":"2021-09-08T07:34:57.895702Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"196/511 [==========>...................] - ETA: 2:08 - loss: 0.2688 - accuracy: 0.9115","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<ipython-input-33-a2a4dacc82ac>\u001b[0m in \u001b[0;36mtrain_pred\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[1477,60] = 53 is not in [0, 53)\n\t [[node model_5/embedding_8/embedding_lookup (defined at <ipython-input-33-a2a4dacc82ac>:3) ]] [Op:__inference_train_function_12024]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_5/embedding_8/embedding_lookup:\n model_5/embedding_8/embedding_lookup/11690 (defined at /opt/conda/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ntrain_function\n"],"ename":"InvalidArgumentError","evalue":" indices[1477,60] = 53 is not in [0, 53)\n\t [[node model_5/embedding_8/embedding_lookup (defined at <ipython-input-33-a2a4dacc82ac>:3) ]] [Op:__inference_train_function_12024]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_5/embedding_8/embedding_lookup:\n model_5/embedding_8/embedding_lookup/11690 (defined at /opt/conda/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ntrain_function\n","output_type":"error"}]},{"cell_type":"markdown","source":"## Choose the best threshold","metadata":{}},{"cell_type":"code","source":"thresholds = []\nfor thresh in np.arange(0.1, 0.501, 0.01):\n    thresh = np.round(thresh, 2)\n    res = metrics.f1_score(y_val, (y_val_pred > thresh).astype(int))\n    thresholds.append([thresh, res])\n    print(\"F! score at threshold {0} is {1}\".format(thresh, res))\n    \nthreholds.sort(key=lambda x: x[1], reverse=True)\nbest_thresh = thresholds[0][0]\nprint(\"Best threshold:\", best_thresh)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:28:43.452619Z","iopub.execute_input":"2021-09-08T07:28:43.453050Z","iopub.status.idle":"2021-09-08T07:28:43.492685Z","shell.execute_reply.started":"2021-09-08T07:28:43.453013Z","shell.execute_reply":"2021-09-08T07:28:43.491366Z"},"trusted":true},"execution_count":26,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-aa3a8b4bdf32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.501\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_val_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mthresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F! score at threshold {0} is {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y_val_pred' is not defined"],"ename":"NameError","evalue":"name 'y_val_pred' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## Confusion matrix of validation output","metadata":{}},{"cell_type":"code","source":"metrics.confusion_matrix(y_val, y_val_pred > best_thresh)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:11:28.538053Z","iopub.status.idle":"2021-09-08T07:11:28.538483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = (y_test_pred > best_thresh).astype(int)\ndf_test = pd.read_csv(\"\", usecols=[\"qid\"])\ndf_out = pd.DataFrame({\"qid\":df_test[\"qid\"].values})\ndf_out['predictions'] = y_test_pred\ndf_out.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:11:28.540577Z","iopub.status.idle":"2021-09-08T07:11:28.541231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# THIS IS AN ERROR, SO I JUST WANT TO SAVE THE PROGRESS ONLY","metadata":{}}]}